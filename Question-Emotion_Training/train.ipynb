{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "from transformers import BertModel\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "# GPU 가 있는 경우 지정\n",
    "device = torch.device(\"cuda:1\")\n",
    "\n",
    "# GPU 가 없는 경우 지정\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "bertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n",
    "vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')\n",
    "tok = tokenizer.tokenize\n",
    "\n",
    "# Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 256\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 120\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len,\n",
    "                 pad, pair):\n",
    "   \n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len,vocab=vocab, pad=pad, pair=pair)\n",
    "        \n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "         \n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=58,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    dataset = [[sentence, '0']]\n",
    "    test = BERTDataset(dataset, 0, 1, tok, vocab, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=batch_size, num_workers=2)\n",
    "    model.eval()\n",
    "    answer = 0\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        for logits in out:\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            answer = np.argmax(logits)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('./custom_chatbotdataset(Training).csv')\n",
    "validation_set = pd.read_csv('./custom_chatbotdataset(Validation).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>일은 왜 해도 해도 끝이 없을까? 화가 난다.</td>\n",
       "      <td>많이 힘드시겠어요. 주위에 의논할 상대가 있나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.</td>\n",
       "      <td>급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...</td>\n",
       "      <td>회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...</td>\n",
       "      <td>관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.</td>\n",
       "      <td>무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>직장에 다니고 있지만 시간만 버리는 거 같아. 진지하게 진로에 대한 고민이 생겨.</td>\n",
       "      <td>진로에 대해서 고민하고 계시는군요. 어떤 점이 고민인가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>성인인데도 진로를 아직도 못 정했다고 부모님이 노여워하셔. 나도 섭섭해.</td>\n",
       "      <td>부모님의 노여움에 섭섭하시군요. 이런 상황을 어떻게 해결하면 좋을까요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>퇴사한 지 얼마 안 됐지만 천천히 직장을 구해보려고.</td>\n",
       "      <td>천천히라도 직장을 구해 보려고 하시는군요. 특별한 이유가 있으신가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>졸업반이라서 취업을 생각해야 하는데 지금 너무 느긋해서 이래도 되나 싶어.</td>\n",
       "      <td>취업에 대해 걱정이 되는군요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>요즘 직장생활이 너무 편하고 좋은 것 같아!</td>\n",
       "      <td>직장생활이 편하고 좋으시다니 좋아 보여요. 다니고 계신 회사만의 장점이 있나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>취업해야 할 나이인데 취업하고 싶지가 않아.</td>\n",
       "      <td>취업하고 싶지 않으시군요. 혹시 어떤 이유가 있을까요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>면접에서 부모님 직업에 대한 질문이 들어왔어.</td>\n",
       "      <td>그때 어떤 생각이 들었나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>큰일이야. 부장님께 결재받아야 하는 서류가 사라졌어. 한 시간 뒤에 제출해야 하는데...</td>\n",
       "      <td>중요한 서류가 사라져서 당혹스러우시군요. 찾아볼 방법이 있을까요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>나 얼마 전에 면접 본 회사에서 면접 합격했다고 연락받았었는데 오늘 다시 입사 취소...</td>\n",
       "      <td>회사에서 합격 통보받았다가 다시 입사 취소되어서 당혹스러우시군요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>길을 가다가 우연히 마주친 동네 아주머니께서 취업했냐고 물어보셔서 당황했어.</td>\n",
       "      <td>취업에 대한 질문이 당혹스러우셨군요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>어제 합격 통보를 받은 회사에서 문자를 잘못 발송했다고 연락이 왔어. 너무 당혹스럽...</td>\n",
       "      <td>잘못 발송된 문자로 당황하셨군요. 사과는 받으셨나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13</td>\n",
       "      <td>나 오늘 첫 출근 했는데 너무 당황스러웠어!</td>\n",
       "      <td>무슨 일 있었나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13</td>\n",
       "      <td>이번에 직장을 이직했는데 글쎄 만나고 싶지 않은 사람을 만나서 아주 당황스럽더라고.</td>\n",
       "      <td>이직하신 직장에서 만나고 싶지 않으신 분을 만나서 많이 당황하신 거 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15</td>\n",
       "      <td>코로나 때문에 뭘 할 수가 없어. 취직 준비를 해야 하는데 시험이 줄줄이 취소되니 ...</td>\n",
       "      <td>코로나로 취업이 어렵군요. 시험도 줄줄이 취소되고요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15</td>\n",
       "      <td>오늘 회사에서 큰 실수를 한 것 같아.</td>\n",
       "      <td>무슨 실수를 하셨나요?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                                  Q  \\\n",
       "0       9                          일은 왜 해도 해도 끝이 없을까? 화가 난다.   \n",
       "1       9     이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.   \n",
       "2       9  회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...   \n",
       "3       9  직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...   \n",
       "4       9              얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.   \n",
       "5       9      직장에 다니고 있지만 시간만 버리는 거 같아. 진지하게 진로에 대한 고민이 생겨.   \n",
       "6       9           성인인데도 진로를 아직도 못 정했다고 부모님이 노여워하셔. 나도 섭섭해.   \n",
       "7      11                      퇴사한 지 얼마 안 됐지만 천천히 직장을 구해보려고.   \n",
       "8       2          졸업반이라서 취업을 생각해야 하는데 지금 너무 느긋해서 이래도 되나 싶어.   \n",
       "9      11                           요즘 직장생활이 너무 편하고 좋은 것 같아!   \n",
       "10     11                           취업해야 할 나이인데 취업하고 싶지가 않아.   \n",
       "11     12                          면접에서 부모님 직업에 대한 질문이 들어왔어.   \n",
       "12     12  큰일이야. 부장님께 결재받아야 하는 서류가 사라졌어. 한 시간 뒤에 제출해야 하는데...   \n",
       "13     12  나 얼마 전에 면접 본 회사에서 면접 합격했다고 연락받았었는데 오늘 다시 입사 취소...   \n",
       "14     13         길을 가다가 우연히 마주친 동네 아주머니께서 취업했냐고 물어보셔서 당황했어.   \n",
       "15     13  어제 합격 통보를 받은 회사에서 문자를 잘못 발송했다고 연락이 왔어. 너무 당혹스럽...   \n",
       "16     13                           나 오늘 첫 출근 했는데 너무 당황스러웠어!   \n",
       "17     13     이번에 직장을 이직했는데 글쎄 만나고 싶지 않은 사람을 만나서 아주 당황스럽더라고.   \n",
       "18     15  코로나 때문에 뭘 할 수가 없어. 취직 준비를 해야 하는데 시험이 줄줄이 취소되니 ...   \n",
       "19     15                              오늘 회사에서 큰 실수를 한 것 같아.   \n",
       "\n",
       "                                                    A  \n",
       "0                         많이 힘드시겠어요. 주위에 의논할 상대가 있나요?  \n",
       "1            급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?  \n",
       "2   회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...  \n",
       "3   관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...  \n",
       "4   무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...  \n",
       "5                    진로에 대해서 고민하고 계시는군요. 어떤 점이 고민인가요?  \n",
       "6            부모님의 노여움에 섭섭하시군요. 이런 상황을 어떻게 해결하면 좋을까요?   \n",
       "7              천천히라도 직장을 구해 보려고 하시는군요. 특별한 이유가 있으신가요?  \n",
       "8                                    취업에 대해 걱정이 되는군요.  \n",
       "9        직장생활이 편하고 좋으시다니 좋아 보여요. 다니고 계신 회사만의 장점이 있나요?  \n",
       "10                     취업하고 싶지 않으시군요. 혹시 어떤 이유가 있을까요?  \n",
       "11                                    그때 어떤 생각이 들었나요?  \n",
       "12               중요한 서류가 사라져서 당혹스러우시군요. 찾아볼 방법이 있을까요?  \n",
       "13               회사에서 합격 통보받았다가 다시 입사 취소되어서 당혹스러우시군요.  \n",
       "14                               취업에 대한 질문이 당혹스러우셨군요.  \n",
       "15                      잘못 발송된 문자로 당황하셨군요. 사과는 받으셨나요?  \n",
       "16                                         무슨 일 있었나요?  \n",
       "17         이직하신 직장에서 만나고 싶지 않으신 분을 만나서 많이 당황하신 거 같아요.  \n",
       "18                      코로나로 취업이 어렵군요. 시험도 줄줄이 취소되고요.  \n",
       "19                                       무슨 실수를 하셨나요?  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_data = [[i, str(j)] for i, j in zip(train_set['Q'], train_set['label'])]\n",
    "validation_set_data = [[i, str(j)] for i, j in zip(validation_set['Q'], validation_set['label'])]\n",
    "\n",
    "train_set_data = BERTDataset(train_set_data, 0, 1, tok, vocab, max_len, True, False)\n",
    "validation_set_data = BERTDataset(validation_set_data, 0, 1, tok, vocab, max_len, True, False)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set_data, batch_size=batch_size, num_workers=2)\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_set_data, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssrlab/ENTER/envs/NLP/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_245590/2876693388.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef2cfdd1d7c4ec39a1eb4bf9e76e044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 4.144363880157471 train acc 0.01953125\n",
      "epoch 1 batch id 201 loss 4.0161824226379395 train acc 0.020522388059701493\n",
      "epoch 1 batch id 401 loss 3.9211533069610596 train acc 0.027713918329177058\n",
      "epoch 1 train acc 0.03182464973730298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_245590/2876693388.py:35: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(validation_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f39d36508a4115a0095d26d47bf4e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.0448393485915493\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438ddbce3b4c410c84f6d7e667f566a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 4.11107873916626 train acc 0.05078125\n",
      "epoch 2 batch id 201 loss 3.437403917312622 train acc 0.11421408582089553\n",
      "epoch 2 batch id 401 loss 3.3541839122772217 train acc 0.11778171758104738\n",
      "epoch 2 train acc 0.10631744488513445\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fae66ca2c17489786bbb32bc400aae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.09628080985915492\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255ee69f318548e2aad49e248c8c2956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 3.9006946086883545 train acc 0.1328125\n",
      "epoch 3 batch id 201 loss 2.7697913646698 train acc 0.24012748756218905\n",
      "epoch 3 batch id 401 loss 2.801152229309082 train acc 0.2171329488778055\n",
      "epoch 3 train acc 0.183953509709488\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510d71685c5b49249aca5e77dbbf456d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.109375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1339392060624d7d9a4ce8ef934dc10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 3.718740701675415 train acc 0.203125\n",
      "epoch 4 batch id 201 loss 2.3249669075012207 train acc 0.30050917288557216\n",
      "epoch 4 batch id 401 loss 2.547844886779785 train acc 0.26494311097256856\n",
      "epoch 4 train acc 0.22301963145152984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e577f9ba52246a0a46a248f310bba55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.12973151408450703\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c17a08cb6049d8bc93d29d56bc66b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 3.445897102355957 train acc 0.20703125\n",
      "epoch 5 batch id 201 loss 2.1477620601654053 train acc 0.33257540422885573\n",
      "epoch 5 batch id 401 loss 2.376643180847168 train acc 0.2935142612219451\n",
      "epoch 5 train acc 0.24947484740393533\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f8438e6f5240278038e71822fc1d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.13721390845070422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26ef8aeebcc4ad69473dc05ac8a5bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 batch id 1 loss 3.3407254219055176 train acc 0.234375\n",
      "epoch 6 batch id 201 loss 2.007582187652588 train acc 0.35962764303482586\n",
      "epoch 6 batch id 401 loss 2.266035318374634 train acc 0.32320565773067333\n",
      "epoch 6 train acc 0.27780652814978885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838747922ea44496b8596f459039331e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 test acc 0.14660357981220656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbb6bbc98124f6ea7aea7e52964c425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 batch id 1 loss 3.108306407928467 train acc 0.265625\n",
      "epoch 7 batch id 201 loss 1.9784644842147827 train acc 0.38969216417910446\n",
      "epoch 7 batch id 401 loss 2.0845694541931152 train acc 0.3533159289276808\n",
      "epoch 7 train acc 0.3080593418409395\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ecfb5b252e14b8297c50d47c2624721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 test acc 0.15056484741784038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42e979369be4e52ad3aa36efe78dd03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 batch id 1 loss 2.881065845489502 train acc 0.31640625\n",
      "epoch 8 batch id 201 loss 1.768722653388977 train acc 0.42014536691542287\n",
      "epoch 8 batch id 401 loss 1.9255218505859375 train acc 0.3856861751870324\n",
      "epoch 8 train acc 0.3403093450602658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f287aeb47070471eade1b42b3f8edd7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 test acc 0.1688306924882629\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba8080eac0f43f0b07d934394831be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 batch id 1 loss 2.6725993156433105 train acc 0.328125\n",
      "epoch 9 batch id 201 loss 1.6568074226379395 train acc 0.4536302860696517\n",
      "epoch 9 batch id 401 loss 1.720716953277588 train acc 0.4198098503740648\n",
      "epoch 9 train acc 0.37458752382301436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461c2389157544c797b54e8ea411de52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 test acc 0.1778719190140845\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a368f5ee37485a9656c8f790b0847c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 batch id 1 loss 2.553565740585327 train acc 0.34375\n",
      "epoch 10 batch id 201 loss 1.4604172706604004 train acc 0.4884561567164179\n",
      "epoch 10 batch id 401 loss 1.6244605779647827 train acc 0.4540017144638404\n",
      "epoch 10 train acc 0.4096725462295251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98eef0a9fb4341f296cb34f8fbae9263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 test acc 0.19069102112676056\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90074b15b21c4d299ccfe880b8678593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 batch id 1 loss 2.3480591773986816 train acc 0.40625\n",
      "epoch 11 batch id 201 loss 1.3661165237426758 train acc 0.519414645522388\n",
      "epoch 11 batch id 401 loss 1.475515604019165 train acc 0.48615765274314215\n",
      "epoch 11 train acc 0.44369720304934585\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d6d652d1d940acae5a13d34720f4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 test acc 0.20327171361502347\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd4230a2c1147c6ac616e1398e9a48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 batch id 1 loss 2.1202218532562256 train acc 0.44921875\n",
      "epoch 12 batch id 201 loss 1.254910945892334 train acc 0.5493625621890548\n",
      "epoch 12 batch id 401 loss 1.3473814725875854 train acc 0.5174563591022444\n",
      "epoch 12 train acc 0.4761995209642526\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218cf48ab02a4043aee537354227d02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 test acc 0.20947036384976528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e3fd7b668540968577bb4833f93c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 batch id 1 loss 2.0054781436920166 train acc 0.4609375\n",
      "epoch 13 batch id 201 loss 1.120219111442566 train acc 0.5814870957711443\n",
      "epoch 13 batch id 401 loss 1.208771824836731 train acc 0.548131624064838\n",
      "epoch 13 train acc 0.5074805069794994\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cfedec86ac64e70801e5d8204e7bb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 test acc 0.22901995305164322\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7678c0e3e7454133a8211f23ab814327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 batch id 1 loss 1.7841709852218628 train acc 0.49609375\n",
      "epoch 14 batch id 201 loss 0.9618239402770996 train acc 0.6092195273631841\n",
      "epoch 14 batch id 401 loss 1.1783982515335083 train acc 0.577842503117207\n",
      "epoch 14 train acc 0.5382620950087565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c016652ae34b63a76e961975ee3896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 test acc 0.24503007629107984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808e72e9524940f093352a2fb8106cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 batch id 1 loss 1.5848830938339233 train acc 0.55859375\n",
      "epoch 15 batch id 201 loss 0.8945237994194031 train acc 0.6280317164179104\n",
      "epoch 15 batch id 401 loss 1.02566659450531 train acc 0.6008611284289277\n",
      "epoch 15 train acc 0.5626368213660246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7baba297d84641f99ed2e6c3fd274aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 test acc 0.2443698650234742\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4681a48ca9dd4c259a86ab5c064597a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 batch id 1 loss 1.4847136735916138 train acc 0.5859375\n",
      "epoch 16 batch id 201 loss 0.8128300309181213 train acc 0.6576103855721394\n",
      "epoch 16 batch id 401 loss 0.9208705425262451 train acc 0.6306012312967582\n",
      "epoch 16 train acc 0.5906167907180385\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173700ce389a40e9828351a74e9f928a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 test acc 0.2429394072769953\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235382af08f7400cb66c7c99c44ba102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 batch id 1 loss 1.3262401819229126 train acc 0.609375\n",
      "epoch 17 batch id 201 loss 0.7739065885543823 train acc 0.6770444651741293\n",
      "epoch 17 batch id 401 loss 0.8602826595306396 train acc 0.6524216801745636\n",
      "epoch 17 train acc 0.6149774325229216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e73cda3852f4b5395922e1cc9fa65a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 test acc 0.2568038438967136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8b839920ff43e8afc4e855469e09c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 batch id 1 loss 1.1700005531311035 train acc 0.66796875\n",
      "epoch 18 batch id 201 loss 0.6470075845718384 train acc 0.6947100435323383\n",
      "epoch 18 batch id 401 loss 0.8617517948150635 train acc 0.6740473036159601\n",
      "epoch 18 train acc 0.6377549706397445\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da36b2ef619144e2a607a755ac4b01b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 test acc 0.2658267312206573\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c67dd5dbb6b406ea67bcb54b2aefa4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 batch id 1 loss 1.0687843561172485 train acc 0.68359375\n",
      "epoch 19 batch id 201 loss 0.5998136401176453 train acc 0.7125893967661692\n",
      "epoch 19 batch id 401 loss 0.7748783826828003 train acc 0.6909873753117207\n",
      "epoch 19 train acc 0.6550528130472855\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585853f873bd4217ae9437696b8031c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 test acc 0.2775454812206573\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657da86a5dfb471995e3f2f7ed33afd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 batch id 1 loss 1.0328667163848877 train acc 0.70703125\n",
      "epoch 20 batch id 201 loss 0.5161911249160767 train acc 0.7278840174129353\n",
      "epoch 20 batch id 401 loss 0.6979258060455322 train acc 0.7096516521197007\n",
      "epoch 20 train acc 0.6733080026012157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c0e4f8b494451881083ebee43dcacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 test acc 0.27844410211267606\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ed5eb44c8c40cdbe0cccba37de3bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 batch id 1 loss 1.0235083103179932 train acc 0.7265625\n",
      "epoch 21 batch id 201 loss 0.5290231108665466 train acc 0.7395638992537313\n",
      "epoch 21 batch id 401 loss 0.6595815420150757 train acc 0.7214483322942643\n",
      "epoch 21 train acc 0.6859676007005254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de2609263564022a9680e97db5d4217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 test acc 0.2887323943661972\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641683050a76412e80c09d6c2ea68968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 batch id 1 loss 0.9042548537254333 train acc 0.7421875\n",
      "epoch 22 batch id 201 loss 0.5082221031188965 train acc 0.7478428171641791\n",
      "epoch 22 batch id 401 loss 0.6061301827430725 train acc 0.7307122817955112\n",
      "epoch 22 train acc 0.6960581764448336\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc04063ff36e406bafbc5f6a86d7c783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 test acc 0.2966182511737089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbf62812d854031a91c7e8b323ab633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 batch id 1 loss 0.8845722079277039 train acc 0.71875\n",
      "epoch 23 batch id 201 loss 0.5000503063201904 train acc 0.7524681281094527\n",
      "epoch 23 batch id 401 loss 0.6529276967048645 train acc 0.7364109258104738\n",
      "epoch 23 train acc 0.702974496497373\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5ce42f4b1541fd90ecc4bf44c53a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 test acc 0.30061619718309857\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0d5dcb791b49e6a48c997b7ed3accf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 batch id 1 loss 0.9143553376197815 train acc 0.73046875\n",
      "epoch 24 batch id 201 loss 0.4266747832298279 train acc 0.7571128731343284\n",
      "epoch 24 batch id 401 loss 0.6733806133270264 train acc 0.7399762312967582\n",
      "epoch 24 train acc 0.7054372810858144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae4b3dc00684c29b54004549d732e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 test acc 0.3260893485915493\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf96f39e2de47fd96207dc0d74dcf1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 batch id 1 loss 0.6778110265731812 train acc 0.796875\n",
      "epoch 25 batch id 201 loss 0.44222381711006165 train acc 0.7555775808457711\n",
      "epoch 25 batch id 401 loss 0.8331544399261475 train acc 0.7401613154613467\n",
      "epoch 25 train acc 0.703812326156382\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2965a23f3e80485a925872a089e865d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 test acc 0.36892972417840375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c154925be1e467ca886041d1ba6b64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 batch id 1 loss 0.7006725072860718 train acc 0.7890625\n",
      "epoch 26 batch id 201 loss 0.5392475724220276 train acc 0.7503109452736318\n",
      "epoch 26 batch id 401 loss 0.833796501159668 train acc 0.7381740960099751\n",
      "epoch 26 train acc 0.7017773095446584\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9035bed4794c558d0af4d632f832b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 test acc 0.4011333626760563\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a4fa57edc541a4ac8ed8a7006cef5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 batch id 1 loss 0.8079248666763306 train acc 0.7734375\n",
      "epoch 27 batch id 201 loss 0.6486412882804871 train acc 0.7513992537313433\n",
      "epoch 27 batch id 401 loss 0.7721672654151917 train acc 0.7383104738154613\n",
      "epoch 27 train acc 0.7000328371278459\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4861d87de394d5a9628b7f5012548f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 test acc 0.4199493838028169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adaa836a4ecd464bab7169eb478d0f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28 batch id 1 loss 0.8659330010414124 train acc 0.75390625\n",
      "epoch 28 batch id 201 loss 0.6811049580574036 train acc 0.7463463930348259\n",
      "epoch 28 batch id 401 loss 0.8918761014938354 train acc 0.7372194513715711\n",
      "epoch 28 train acc 0.6998686514886164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdab7440a5a045af89bf4c559fd87e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28 test acc 0.43375880281690143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e7a70108814c2d8cc7ee59b252d94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29 batch id 1 loss 0.8967325091362 train acc 0.73046875\n",
      "epoch 29 batch id 201 loss 0.7958365082740784 train acc 0.7412546641791045\n",
      "epoch 29 batch id 401 loss 0.9693502187728882 train acc 0.738086424563591\n",
      "epoch 29 train acc 0.6995197570052539\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8aec11bb6748598cfaaeb3d9cb3988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29 test acc 0.4467612969483568\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835b718a2b9442cf8f7f66d45a17c476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 batch id 1 loss 0.9386646151542664 train acc 0.7265625\n",
      "epoch 30 batch id 201 loss 0.7189372181892395 train acc 0.7489699937810945\n",
      "epoch 30 batch id 401 loss 1.0745476484298706 train acc 0.7455872038653366\n",
      "epoch 30 train acc 0.7064018717162872\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec54e2c23bd049549ef3d18b111a6cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 test acc 0.44989730046948356\n"
     ]
    }
   ],
   "source": [
    "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)\n",
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    best_test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(validation_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
    "    \n",
    "    if(best_test_acc < test_acc):\n",
    "        best_test_acc = test_acc\n",
    "        torch.save({\n",
    "            'model' : model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }, './save_model/QtEmodel{}.pth'.format(e+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(predict_sentence):\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, vocab, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size = batch_size, num_workers = 4)\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        \n",
    "        valid_length = valid_length\n",
    "        label = label.long().to(device)\n",
    "        \n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_eval = []\n",
    "        for i in out:\n",
    "            logits = i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            test_eval.append([np.argmax(logits)])\n",
    "            \n",
    "        print(\">> 입력하신 내용은 \" , test_eval[0] , \"입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용은  [29] 입니다.\n"
     ]
    }
   ],
   "source": [
    "predict('나 지금 매우 신난다')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kyuwon_video_swin_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
