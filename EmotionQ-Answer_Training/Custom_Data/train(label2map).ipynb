{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_TKN = \"<usr>\"\n",
    "A_TKN = \"<sys>\"\n",
    "BOS = '</s>'\n",
    "EOS = '</s>'\n",
    "MASK = '<unused0>'\n",
    "SENT = '<unused1>'\n",
    "PAD = '<pad>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "            bos_token=BOS, eos_token=EOS, unk_token='<unk>',\n",
    "            pad_token=PAD, mask_token=MASK) \n",
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chatbot_Data = pd.read_csv(\"../../Data_preprocessing/custom_chatbotdataset(Training).csv\")\n",
    "Chatbot_Data_validation = pd.read_csv(\"../../Data_preprocessing/custom_chatbotdataset(Validation).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145954, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chatbot_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>일은 왜 해도 해도 끝이 없을까? 화가 난다.</td>\n",
       "      <td>많이 힘드시겠어요. 주위에 의논할 상대가 있나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.</td>\n",
       "      <td>급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...</td>\n",
       "      <td>회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...</td>\n",
       "      <td>관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.</td>\n",
       "      <td>무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>직장에 다니고 있지만 시간만 버리는 거 같아. 진지하게 진로에 대한 고민이 생겨.</td>\n",
       "      <td>진로에 대해서 고민하고 계시는군요. 어떤 점이 고민인가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>성인인데도 진로를 아직도 못 정했다고 부모님이 노여워하셔. 나도 섭섭해.</td>\n",
       "      <td>부모님의 노여움에 섭섭하시군요. 이런 상황을 어떻게 해결하면 좋을까요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>퇴사한 지 얼마 안 됐지만 천천히 직장을 구해보려고.</td>\n",
       "      <td>천천히라도 직장을 구해 보려고 하시는군요. 특별한 이유가 있으신가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>졸업반이라서 취업을 생각해야 하는데 지금 너무 느긋해서 이래도 되나 싶어.</td>\n",
       "      <td>취업에 대해 걱정이 되는군요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>요즘 직장생활이 너무 편하고 좋은 것 같아!</td>\n",
       "      <td>직장생활이 편하고 좋으시다니 좋아 보여요. 다니고 계신 회사만의 장점이 있나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>취업해야 할 나이인데 취업하고 싶지가 않아.</td>\n",
       "      <td>취업하고 싶지 않으시군요. 혹시 어떤 이유가 있을까요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>면접에서 부모님 직업에 대한 질문이 들어왔어.</td>\n",
       "      <td>그때 어떤 생각이 들었나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>큰일이야. 부장님께 결재받아야 하는 서류가 사라졌어. 한 시간 뒤에 제출해야 하는데...</td>\n",
       "      <td>중요한 서류가 사라져서 당혹스러우시군요. 찾아볼 방법이 있을까요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>나 얼마 전에 면접 본 회사에서 면접 합격했다고 연락받았었는데 오늘 다시 입사 취소...</td>\n",
       "      <td>회사에서 합격 통보받았다가 다시 입사 취소되어서 당혹스러우시군요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>길을 가다가 우연히 마주친 동네 아주머니께서 취업했냐고 물어보셔서 당황했어.</td>\n",
       "      <td>취업에 대한 질문이 당혹스러우셨군요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>어제 합격 통보를 받은 회사에서 문자를 잘못 발송했다고 연락이 왔어. 너무 당혹스럽...</td>\n",
       "      <td>잘못 발송된 문자로 당황하셨군요. 사과는 받으셨나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13</td>\n",
       "      <td>나 오늘 첫 출근 했는데 너무 당황스러웠어!</td>\n",
       "      <td>무슨 일 있었나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13</td>\n",
       "      <td>이번에 직장을 이직했는데 글쎄 만나고 싶지 않은 사람을 만나서 아주 당황스럽더라고.</td>\n",
       "      <td>이직하신 직장에서 만나고 싶지 않으신 분을 만나서 많이 당황하신 거 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15</td>\n",
       "      <td>코로나 때문에 뭘 할 수가 없어. 취직 준비를 해야 하는데 시험이 줄줄이 취소되니 ...</td>\n",
       "      <td>코로나로 취업이 어렵군요. 시험도 줄줄이 취소되고요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15</td>\n",
       "      <td>오늘 회사에서 큰 실수를 한 것 같아.</td>\n",
       "      <td>무슨 실수를 하셨나요?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                                  Q  \\\n",
       "0       9                          일은 왜 해도 해도 끝이 없을까? 화가 난다.   \n",
       "1       9     이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.   \n",
       "2       9  회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...   \n",
       "3       9  직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...   \n",
       "4       9              얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.   \n",
       "5       9      직장에 다니고 있지만 시간만 버리는 거 같아. 진지하게 진로에 대한 고민이 생겨.   \n",
       "6       9           성인인데도 진로를 아직도 못 정했다고 부모님이 노여워하셔. 나도 섭섭해.   \n",
       "7      11                      퇴사한 지 얼마 안 됐지만 천천히 직장을 구해보려고.   \n",
       "8       2          졸업반이라서 취업을 생각해야 하는데 지금 너무 느긋해서 이래도 되나 싶어.   \n",
       "9      11                           요즘 직장생활이 너무 편하고 좋은 것 같아!   \n",
       "10     11                           취업해야 할 나이인데 취업하고 싶지가 않아.   \n",
       "11     12                          면접에서 부모님 직업에 대한 질문이 들어왔어.   \n",
       "12     12  큰일이야. 부장님께 결재받아야 하는 서류가 사라졌어. 한 시간 뒤에 제출해야 하는데...   \n",
       "13     12  나 얼마 전에 면접 본 회사에서 면접 합격했다고 연락받았었는데 오늘 다시 입사 취소...   \n",
       "14     13         길을 가다가 우연히 마주친 동네 아주머니께서 취업했냐고 물어보셔서 당황했어.   \n",
       "15     13  어제 합격 통보를 받은 회사에서 문자를 잘못 발송했다고 연락이 왔어. 너무 당혹스럽...   \n",
       "16     13                           나 오늘 첫 출근 했는데 너무 당황스러웠어!   \n",
       "17     13     이번에 직장을 이직했는데 글쎄 만나고 싶지 않은 사람을 만나서 아주 당황스럽더라고.   \n",
       "18     15  코로나 때문에 뭘 할 수가 없어. 취직 준비를 해야 하는데 시험이 줄줄이 취소되니 ...   \n",
       "19     15                              오늘 회사에서 큰 실수를 한 것 같아.   \n",
       "\n",
       "                                                    A  \n",
       "0                         많이 힘드시겠어요. 주위에 의논할 상대가 있나요?  \n",
       "1            급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?  \n",
       "2   회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...  \n",
       "3   관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...  \n",
       "4   무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...  \n",
       "5                    진로에 대해서 고민하고 계시는군요. 어떤 점이 고민인가요?  \n",
       "6            부모님의 노여움에 섭섭하시군요. 이런 상황을 어떻게 해결하면 좋을까요?   \n",
       "7              천천히라도 직장을 구해 보려고 하시는군요. 특별한 이유가 있으신가요?  \n",
       "8                                    취업에 대해 걱정이 되는군요.  \n",
       "9        직장생활이 편하고 좋으시다니 좋아 보여요. 다니고 계신 회사만의 장점이 있나요?  \n",
       "10                     취업하고 싶지 않으시군요. 혹시 어떤 이유가 있을까요?  \n",
       "11                                    그때 어떤 생각이 들었나요?  \n",
       "12               중요한 서류가 사라져서 당혹스러우시군요. 찾아볼 방법이 있을까요?  \n",
       "13               회사에서 합격 통보받았다가 다시 입사 취소되어서 당혹스러우시군요.  \n",
       "14                               취업에 대한 질문이 당혹스러우셨군요.  \n",
       "15                      잘못 발송된 문자로 당황하셨군요. 사과는 받으셨나요?  \n",
       "16                                         무슨 일 있었나요?  \n",
       "17         이직하신 직장에서 만나고 싶지 않으신 분을 만나서 많이 당황하신 거 같아요.  \n",
       "18                      코로나로 취업이 어렵군요. 시험도 줄줄이 취소되고요.  \n",
       "19                                       무슨 실수를 하셨나요?  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chatbot_Data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 주어진 감정 딕셔너리\n",
    "# emotion_map = {\n",
    "#     '노여워하는': 9, '느긋': 11, '걱정스러운': 2, '당혹스러운': 12, '당황': 13, '마비된': 15,\n",
    "#     '만족스러운': 16, '배신당한': 18, '버려진': 19, '부끄러운': 20, '분노': 21, '불안': 22,\n",
    "#     '비통한': 23, '상처': 24, '성가신': 25, '스트레스 받는': 26, '슬픔': 27, '신뢰하는': 28,\n",
    "#     '신이 난': 29, '실망한': 30, '악의적인': 31, '안달하는': 32, '안도': 33, '억울한': 34,\n",
    "#     '열등감': 35, '염세적인': 36, '외로운': 37, '우울한': 38, '고립된': 3, '좌절한': 41,\n",
    "#     '후회되는': 55, '혐오스러운': 51, '한심한': 50, '자신하는': 39, '기쁨': 6, '툴툴대는': 48,\n",
    "#     '남의 시선을 의식하는': 8, '회의적인': 54, '죄책감의': 42, '혼란스러운': 52, '초조한': 45,\n",
    "#     '흥분': 56, '충격 받은': 46, '취약한': 47, '편안한': 49, '방어적인': 17, '질투하는': 43,\n",
    "#     '두려운': 14, '눈물이 나는': 10, '짜증내는': 44, '조심스러운': 40, '낙담한': 7,\n",
    "#     '환멸을 느끼는': 53, '희생된': 57, '감사하는': 1, '구역질 나는': 5, '괴로워하는': 4,\n",
    "#     '가난한, 불우한': 0\n",
    "# }\n",
    "\n",
    "emotion2Token_map = {\n",
    "    9: '<unused10>', 11: '<unused11>', 2: '<unused12>', 12: '<unused13>', 13: '<unused14>', 15: '<unused15>',\n",
    "    16: '<unused16>', 18: '<unused17>', 19: '<unused18>', 20: '<unused19>', 21: '<unused20>', 22: '<unused21>',\n",
    "    23: '<unused22>', 24: '<unused23>', 25: '<unused24>', 26: '<unused25>', 27: '<unused26>', 28: '<unused27>',\n",
    "    29: '<unused28>', 30: '<unused29>', 31: '<unused30>', 32: '<unused31>', 33: '<unused32>', 34: '<unused33>',\n",
    "    35: '<unused34>', 36: '<unused35>', 37: '<unused36>', 38: '<unused37>', 3: '<unused38>', 41: '<unused39>',\n",
    "    55: '<unused40>', 51: '<unused41>', 50: '<unused42>', 39: '<unused43>', 6: '<unused44>', 48: '<unused45>',\n",
    "    8: '<unused46>', 54: '<unused47>', 42: '<unused48>', 52: '<unused49>', 45: '<unused50>', 56: '<unused51>',\n",
    "    46: '<unused52>', 47: '<unused53>', 49: '<unused54>', 17: '<unused55>', 43: '<unused56>', 14: '<unused57>',\n",
    "    10: '<unused58>', 44: '<unused59>', 40: '<unused60>', 7: '<unused61>', 53: '<unused62>', 57: '<unused63>',\n",
    "    1: '<unused64>', 5: '<unused65>', 4: '<unused66>', 0: '<unused67>'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(58):\n",
    "    Chatbot_Data.replace({'label' :i}, emotion2Token_map[i], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unused10&gt;</td>\n",
       "      <td>일은 왜 해도 해도 끝이 없을까? 화가 난다.</td>\n",
       "      <td>많이 힘드시겠어요. 주위에 의논할 상대가 있나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;unused10&gt;</td>\n",
       "      <td>이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.</td>\n",
       "      <td>급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;unused10&gt;</td>\n",
       "      <td>회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...</td>\n",
       "      <td>회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;unused10&gt;</td>\n",
       "      <td>직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...</td>\n",
       "      <td>관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;unused10&gt;</td>\n",
       "      <td>얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.</td>\n",
       "      <td>무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;unused10&gt;</td>\n",
       "      <td>직장에 다니고 있지만 시간만 버리는 거 같아. 진지하게 진로에 대한 고민이 생겨.</td>\n",
       "      <td>진로에 대해서 고민하고 계시는군요. 어떤 점이 고민인가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;unused10&gt;</td>\n",
       "      <td>성인인데도 진로를 아직도 못 정했다고 부모님이 노여워하셔. 나도 섭섭해.</td>\n",
       "      <td>부모님의 노여움에 섭섭하시군요. 이런 상황을 어떻게 해결하면 좋을까요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;unused11&gt;</td>\n",
       "      <td>퇴사한 지 얼마 안 됐지만 천천히 직장을 구해보려고.</td>\n",
       "      <td>천천히라도 직장을 구해 보려고 하시는군요. 특별한 이유가 있으신가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;unused12&gt;</td>\n",
       "      <td>졸업반이라서 취업을 생각해야 하는데 지금 너무 느긋해서 이래도 되나 싶어.</td>\n",
       "      <td>취업에 대해 걱정이 되는군요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;unused11&gt;</td>\n",
       "      <td>요즘 직장생활이 너무 편하고 좋은 것 같아!</td>\n",
       "      <td>직장생활이 편하고 좋으시다니 좋아 보여요. 다니고 계신 회사만의 장점이 있나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;unused11&gt;</td>\n",
       "      <td>취업해야 할 나이인데 취업하고 싶지가 않아.</td>\n",
       "      <td>취업하고 싶지 않으시군요. 혹시 어떤 이유가 있을까요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;unused13&gt;</td>\n",
       "      <td>면접에서 부모님 직업에 대한 질문이 들어왔어.</td>\n",
       "      <td>그때 어떤 생각이 들었나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;unused13&gt;</td>\n",
       "      <td>큰일이야. 부장님께 결재받아야 하는 서류가 사라졌어. 한 시간 뒤에 제출해야 하는데...</td>\n",
       "      <td>중요한 서류가 사라져서 당혹스러우시군요. 찾아볼 방법이 있을까요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;unused13&gt;</td>\n",
       "      <td>나 얼마 전에 면접 본 회사에서 면접 합격했다고 연락받았었는데 오늘 다시 입사 취소...</td>\n",
       "      <td>회사에서 합격 통보받았다가 다시 입사 취소되어서 당혹스러우시군요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;unused14&gt;</td>\n",
       "      <td>길을 가다가 우연히 마주친 동네 아주머니께서 취업했냐고 물어보셔서 당황했어.</td>\n",
       "      <td>취업에 대한 질문이 당혹스러우셨군요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;unused14&gt;</td>\n",
       "      <td>어제 합격 통보를 받은 회사에서 문자를 잘못 발송했다고 연락이 왔어. 너무 당혹스럽...</td>\n",
       "      <td>잘못 발송된 문자로 당황하셨군요. 사과는 받으셨나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;unused14&gt;</td>\n",
       "      <td>나 오늘 첫 출근 했는데 너무 당황스러웠어!</td>\n",
       "      <td>무슨 일 있었나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;unused14&gt;</td>\n",
       "      <td>이번에 직장을 이직했는데 글쎄 만나고 싶지 않은 사람을 만나서 아주 당황스럽더라고.</td>\n",
       "      <td>이직하신 직장에서 만나고 싶지 않으신 분을 만나서 많이 당황하신 거 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;unused15&gt;</td>\n",
       "      <td>코로나 때문에 뭘 할 수가 없어. 취직 준비를 해야 하는데 시험이 줄줄이 취소되니 ...</td>\n",
       "      <td>코로나로 취업이 어렵군요. 시험도 줄줄이 취소되고요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;unused15&gt;</td>\n",
       "      <td>오늘 회사에서 큰 실수를 한 것 같아.</td>\n",
       "      <td>무슨 실수를 하셨나요?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                                  Q  \\\n",
       "0   <unused10>                          일은 왜 해도 해도 끝이 없을까? 화가 난다.   \n",
       "1   <unused10>     이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.   \n",
       "2   <unused10>  회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...   \n",
       "3   <unused10>  직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...   \n",
       "4   <unused10>              얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.   \n",
       "5   <unused10>      직장에 다니고 있지만 시간만 버리는 거 같아. 진지하게 진로에 대한 고민이 생겨.   \n",
       "6   <unused10>           성인인데도 진로를 아직도 못 정했다고 부모님이 노여워하셔. 나도 섭섭해.   \n",
       "7   <unused11>                      퇴사한 지 얼마 안 됐지만 천천히 직장을 구해보려고.   \n",
       "8   <unused12>          졸업반이라서 취업을 생각해야 하는데 지금 너무 느긋해서 이래도 되나 싶어.   \n",
       "9   <unused11>                           요즘 직장생활이 너무 편하고 좋은 것 같아!   \n",
       "10  <unused11>                           취업해야 할 나이인데 취업하고 싶지가 않아.   \n",
       "11  <unused13>                          면접에서 부모님 직업에 대한 질문이 들어왔어.   \n",
       "12  <unused13>  큰일이야. 부장님께 결재받아야 하는 서류가 사라졌어. 한 시간 뒤에 제출해야 하는데...   \n",
       "13  <unused13>  나 얼마 전에 면접 본 회사에서 면접 합격했다고 연락받았었는데 오늘 다시 입사 취소...   \n",
       "14  <unused14>         길을 가다가 우연히 마주친 동네 아주머니께서 취업했냐고 물어보셔서 당황했어.   \n",
       "15  <unused14>  어제 합격 통보를 받은 회사에서 문자를 잘못 발송했다고 연락이 왔어. 너무 당혹스럽...   \n",
       "16  <unused14>                           나 오늘 첫 출근 했는데 너무 당황스러웠어!   \n",
       "17  <unused14>     이번에 직장을 이직했는데 글쎄 만나고 싶지 않은 사람을 만나서 아주 당황스럽더라고.   \n",
       "18  <unused15>  코로나 때문에 뭘 할 수가 없어. 취직 준비를 해야 하는데 시험이 줄줄이 취소되니 ...   \n",
       "19  <unused15>                              오늘 회사에서 큰 실수를 한 것 같아.   \n",
       "\n",
       "                                                    A  \n",
       "0                         많이 힘드시겠어요. 주위에 의논할 상대가 있나요?  \n",
       "1            급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?  \n",
       "2   회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...  \n",
       "3   관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...  \n",
       "4   무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...  \n",
       "5                    진로에 대해서 고민하고 계시는군요. 어떤 점이 고민인가요?  \n",
       "6            부모님의 노여움에 섭섭하시군요. 이런 상황을 어떻게 해결하면 좋을까요?   \n",
       "7              천천히라도 직장을 구해 보려고 하시는군요. 특별한 이유가 있으신가요?  \n",
       "8                                    취업에 대해 걱정이 되는군요.  \n",
       "9        직장생활이 편하고 좋으시다니 좋아 보여요. 다니고 계신 회사만의 장점이 있나요?  \n",
       "10                     취업하고 싶지 않으시군요. 혹시 어떤 이유가 있을까요?  \n",
       "11                                    그때 어떤 생각이 들었나요?  \n",
       "12               중요한 서류가 사라져서 당혹스러우시군요. 찾아볼 방법이 있을까요?  \n",
       "13               회사에서 합격 통보받았다가 다시 입사 취소되어서 당혹스러우시군요.  \n",
       "14                               취업에 대한 질문이 당혹스러우셨군요.  \n",
       "15                      잘못 발송된 문자로 당황하셨군요. 사과는 받으셨나요?  \n",
       "16                                         무슨 일 있었나요?  \n",
       "17         이직하신 직장에서 만나고 싶지 않으신 분을 만나서 많이 당황하신 거 같아요.  \n",
       "18                      코로나로 취업이 어렵군요. 시험도 줄줄이 취소되고요.  \n",
       "19                                       무슨 실수를 하셨나요?  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chatbot_Data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self, chats, max_len=40):  # 데이터셋의 전처리를 해주는 부분\n",
    "        self._data = chats\n",
    "        self.max_len = max_len\n",
    "        self.q_token = Q_TKN\n",
    "        self.a_token = A_TKN\n",
    "        self.sent_token = SENT\n",
    "        self.eos = EOS\n",
    "        self.mask = MASK\n",
    "        self.tokenizer = koGPT2_TOKENIZER\n",
    "\n",
    "    def __len__(self):  # chatbotdata 의 길이를 리턴한다.\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, idx):  # 로드한 챗봇 데이터를 차례차례 DataLoader로 넘겨주는 메서드\n",
    "        turn = self._data.iloc[idx]\n",
    "        \n",
    "        emotion = turn[\"label\"]\n",
    "        \n",
    "        q = turn[\"Q\"]  # 질문을 가져온다.\n",
    "        q = re.sub(r\"([?.!,])\", r\" \", q)  # 구둣점들을 제거한다.\n",
    "\n",
    "        a = turn[\"A\"]  # 답변을 가져온다.\n",
    "        a = re.sub(r\"([?.!,])\", r\" \", a)  # 구둣점들을 제거한다.\n",
    "\n",
    "        q_toked = self.tokenizer.tokenize(emotion + self.sent_token + self.q_token + q + self.sent_token)\n",
    "        q_len = len(q_toked)\n",
    "\n",
    "        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n",
    "        a_len = len(a_toked)\n",
    "\n",
    "        #질문의 길이가 최대길이보다 크면\n",
    "        if q_len > self.max_len:\n",
    "            a_len = self.max_len - q_len        #답변의 길이를 최대길이 - 질문길이\n",
    "            if a_len <= 0:       #질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\n",
    "                q_toked = q_toked[-(int(self.max_len / 2)) :]   #질문길이를 최대길이의 반으로 \n",
    "                q_len = len(q_toked)\n",
    "                a_len = self.max_len - q_len              #답변의 길이를 최대길이 - 질문길이\n",
    "            a_toked = a_toked[:a_len]\n",
    "            a_len = len(a_toked)\n",
    "\n",
    "        #질문의 길이 + 답변의 길이가 최대길이보다 크면\n",
    "        if q_len + a_len > self.max_len:\n",
    "            a_len = self.max_len - q_len        #답변의 길이를 최대길이 - 질문길이\n",
    "            if a_len <= 0:       #질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\n",
    "                q_toked = q_toked[-(int(self.max_len / 2)) :]   #질문길이를 최대길이의 반으로 \n",
    "                q_len = len(q_toked)\n",
    "                a_len = self.max_len - q_len              #답변의 길이를 최대길이 - 질문길이\n",
    "            a_toked = a_toked[:a_len]\n",
    "            a_len = len(a_toked)\n",
    "\n",
    "        # 답변 labels = [mask, mask, ...., mask, ..., <bos>,..답변.. <eos>, <pad>....]\n",
    "        labels = [self.mask,] * q_len + a_toked[1:]\n",
    "\n",
    "        # mask = 질문길이 0 + 답변길이 1 + 나머지 0\n",
    "        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n",
    "        # 답변 labels을 index 로 만든다.\n",
    "        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n",
    "        # 최대길이만큼 PADDING\n",
    "        while len(labels_ids) < self.max_len:\n",
    "            labels_ids += [self.tokenizer.pad_token_id]\n",
    "\n",
    "        # 질문 + 답변을 index 로 만든다.    \n",
    "        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n",
    "        # 최대길이만큼 PADDING\n",
    "        while len(token_ids) < self.max_len:\n",
    "            token_ids += [self.tokenizer.pad_token_id]\n",
    "\n",
    "        #질문+답변, 마스크, 답변\n",
    "        return (np.array(token_ids), np.array(mask), np.array(labels_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ChatbotDataset(Chatbot_Data, max_len=40)\n",
    "train_dataloader = DataLoader(train_set, batch_size=128, num_workers=4, shuffle=False)\n",
    "\n",
    "valid_set = ChatbotDataset(Chatbot_Data_validation, max_len=40)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=128, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-5\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epoch = 120\n",
    "Sneg = -1e18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "100%|██████████| 1141/1141 [03:11<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train loss = 20.41384506225586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:09<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, validation loss = 19.894577026367188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1141/1141 [03:11<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, train loss = 20.215761184692383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:09<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, validation loss = 19.797515869140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1141/1141 [03:12<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, train loss = 20.114200592041016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:09<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, validation loss = 19.754491806030273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1141/1141 [03:12<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, train loss = 20.028221130371094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:09<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, validation loss = 19.736541748046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1141/1141 [03:12<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, train loss = 19.947525024414062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:09<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, validation loss = 19.728927612304688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 990/1141 [02:46<00:25,  5.95it/s]"
     ]
    }
   ],
   "source": [
    "print (\"start\")\n",
    "for epoch in range(epoch):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for samples in tqdm(train_dataloader): # train\n",
    "        optimizer.zero_grad()\n",
    "        token_ids, mask, label = samples\n",
    "        \n",
    "        token_ids = token_ids.to(device)\n",
    "        mask = mask.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        out = model(token_ids)\n",
    "        \n",
    "        out = out.logits      #Returns a new tensor with the logit of the elements of input\n",
    "        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n",
    "        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n",
    "        loss = criterion(mask_out.transpose(2, 1), label)\n",
    "        # 평균 loss 만들기 avg_loss[0] / avg_loss[1] <- loss 정규화\n",
    "        avg_loss = loss.sum() / mask.sum()\n",
    "        avg_loss.backward()\n",
    "        # 학습 끝\n",
    "        optimizer.step()\n",
    "        train_loss += avg_loss\n",
    "    train_loss = ((train_loss) / len(train_dataloader))\n",
    "    print('Epoch = {}, train loss = {}'.format((epoch+1), train_loss))\n",
    "        \n",
    "    with torch.no_grad(): # validation\n",
    "        model.eval()\n",
    "        for samples in tqdm(valid_dataloader):\n",
    "            token_ids, mask, label = samples\n",
    "            \n",
    "            token_ids = token_ids.to(device)\n",
    "            mask = mask.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            out = model(token_ids)\n",
    "            \n",
    "            out = out.logits\n",
    "            mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n",
    "            mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n",
    "            loss = criterion(mask_out.transpose(2, 1), label)\n",
    "            \n",
    "            avg_loss = loss.sum() / mask.sum()\n",
    "\n",
    "            valid_loss += avg_loss\n",
    "        valid_loss = ((valid_loss) / len(valid_dataloader))\n",
    "        print('Epoch = {}, validation loss = {}'.format((epoch+1), valid_loss))\n",
    "            \n",
    "print (\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "            }, 'model_EQ2A_Custom_Data_label2map_{}_.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 챗봇 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    while 1:\n",
    "        q = input(\"user > \").strip()\n",
    "        if q == \"quit\":\n",
    "            break\n",
    "        a = \"\"\n",
    "        while 1:\n",
    "            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q + SENT + '0' + A_TKN + a)).unsqueeze(dim=0)\n",
    "            pred = model(input_ids.to(device))\n",
    "            pred = pred.logits\n",
    "            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().cpu().numpy().tolist())[-1]\n",
    "            if gen == EOS:\n",
    "                break\n",
    "            a += gen.replace(\"▁\", \" \")\n",
    "        print(\"Chatbot > {}\".format(a.strip()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
