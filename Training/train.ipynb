{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gluonnlp in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (0.10.0)\n",
      "Requirement already satisfied: pandas in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: tqdm in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/ssrlab/.local/lib/python3.10/site-packages (from gluonnlp) (1.23.5)\n",
      "Requirement already satisfied: cython in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from gluonnlp) (0.29.34)\n",
      "Requirement already satisfied: packaging in /home/ssrlab/.local/lib/python3.10/site-packages (from gluonnlp) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ssrlab/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: mxnet in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (1.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /home/ssrlab/.local/lib/python3.10/site-packages (from mxnet) (1.23.5)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from mxnet) (2.30.0)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from requests<3,>=2.20.0->mxnet) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from requests<3,>=2.20.0->mxnet) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from requests<3,>=2.20.0->mxnet) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from requests<3,>=2.20.0->mxnet) (2023.5.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (0.1.99)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: transformers in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (4.30.2)\n",
      "Requirement already satisfied: filelock in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ssrlab/.local/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ssrlab/.local/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from transformers) (2.30.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ssrlab/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from requests->transformers) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ssrlab/.local/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (66.0.0)\n",
      "Requirement already satisfied: wheel in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ssrlab/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting kobert_tokenizer\n",
      "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-mddon814/kobert-tokenizer_04678a4262bf40ebb9aefbd0bc4e1d19\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-mddon814/kobert-tokenizer_04678a4262bf40ebb9aefbd0bc4e1d19\n",
      "  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# # 라이브러리 설치\n",
    "# !pip install gluonnlp pandas tqdm   \n",
    "# !pip install mxnet\n",
    "# !pip install sentencepiece\n",
    "# !pip install transformers\n",
    "# !pip install torch\n",
    "# !pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n",
    "\n",
    "# 사용한 아나콘다 가상 환경\n",
    "# kw_sw (Python 3.8.16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "from transformers import BertModel\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "# GPU 가 있는 경우 지정\n",
    "# device = torch.device(\"cuda:1\")\n",
    "device = torch.device(\"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "bertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n",
    "vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')\n",
    "tok = tokenizer.tokenize\n",
    "\n",
    "# Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 128\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 30\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len,\n",
    "                 pad, pair):\n",
    "   \n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len,vocab=vocab, pad=pad, pair=pair)\n",
    "        \n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "         \n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=58,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    dataset = [[sentence, '0']]\n",
    "    test = BERTDataset(dataset, 0, 1, tok, vocab, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=batch_size, num_workers=2)\n",
    "    model.eval()\n",
    "    answer = 0\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        for logits in out:\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            answer = np.argmax(logits)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('./custom_chatbotdataset(Training).csv')\n",
    "validation_set = pd.read_csv('./custom_chatbotdataset(Validation).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_data = [[i, str(j)] for i, j in zip(train_set['Q'], train_set['label'])]\n",
    "validation_set_data = [[i, str(j)] for i, j in zip(validation_set['Q'], validation_set['label'])]\n",
    "\n",
    "train_set_data = BERTDataset(train_set_data, 0, 1, tok, vocab, max_len, True, False)\n",
    "validation_set_data = BERTDataset(validation_set_data, 0, 1, tok, vocab, max_len, True, False)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set_data, batch_size=batch_size, num_workers=2)\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_set_data, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)\n",
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(validation_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kyuwon_video_swin_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
